\section{Implementation} \label{implementation}
Below are the different components which have been implemented to support this research. The entire implementation exists inside the Breda repository and is written in rust and HLSL, this is why all code samples also use these langauges.

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/vdb_asset.png}
    \caption{VDB asset data structure. Each VDB asset has constants for the entire animation, and density data. This density data has all the constants, nodes and voxel data. This voxel data can either be in buffer or texture layout. }
    \label{fig:vdb_asset}
\end{wrapfigure}

\subsection{Asset pipeline} \label{implementation:asset_pipeline}
The Breda asset pipeline is used to load all VDB files. This allows us to specify how our assets are loaded and processed, along with caching our final assets to reduce the amount of rebuilding. The main tweakable options for our VDB asset processing pipeline are the format, grid, filenames and clustering options. Format can be any of 32bit floating point, 16bit floating point, unsigned normalized (8bit float between 0 and 1) and BC7 \ref{introduction:texture_compression}. The grid specifies which grid in the VDB file we use as our density data. Usually there are multiple grids in each VDB file, we can have density, temperature and volume type for example. All of these grids are used for different parts in a rendering pipeline, but for this research we are only interested in a single grid and that is the density grid. The filenames option is used to select one or multiple VDB files, when entering multiple filenames we assume that these are an animation sequence. The clustering options consist of three things: (1) number of clusters, which is $k$ when running k-means. (2) The number of iterations of k-means. And (3) the variance rejection threshold, which is used to specify how heterogeneous our bricks can be before we stop clustering them.

\begin{wrapfigure}{r}{0.5\textwidth}
    \centering
    \includegraphics[width=\linewidth]{figures/voxel_memory_view.png}
    \caption{Voxel data texture captured by the Nsight frame debugger. Tiles of $8\times 8$ pixels can be seen. The third dimension, to get our brick data, is encoded using the rgba color channels and the next texture slice. The tiles often contain grey values, meaning that the voxels in the z axis are roughly the same (a pixel with roughly similar color values will always be a greyscale). However, some of the pixels have bright colors, this means that not all color channels were the same and there is either one voxel in the z axis which is significantly different, or there is a gradient. This slice of the voxel brick data also showcases that even on this small scale of the individual brick level, there are many high frequency details.}
    \label{fig:vdb_asset:memory_view}
\end{wrapfigure}


Using these options we can compute our VDB asset. This consists mostly of constants and GPU-friendly vectors of data (see Figure \ref{fig:vdb_asset}). All nodes are implemented as structs which contain an unsigned integer to point into the next level of nodes, and an array which contains unsigned integers. These are interpreted as the active child bitmasks. In code we refer to the internal nodes as L1, L2 and L3 nodes. L1 being the top level node with size $(1 << 5)^3$, L2 having size $(1 << 4)^3$ and L3 having size $(1 << 3)^3$ and pointing into the voxel data. The diffferent animation frames are all unique L1 nodes. So if we want to render a specific frame we can simply take the frame id and use that to index into the L1 nodes buffer, all pointers after that are handled at the asset creation stage.

The actual asset creation process has a few steps. First we read the metadata of our VDB files. We then use these to select which grid we want to read, after which we load the VDB data using vdb-rs \cite{VDBRS} which was developed during this research. Then we transform this data into our flat GPU friendly data. After which we perform our post processing transformations. We first run our deduplication scheme described in Section \ref{approach:clustering_similar_nodes}. After this we transform our data layout from our easy (and locally coherent) buffer layout, to the texture layout. Then, depending on which format options were used, we compress our data. So we reduce our floating point data to either 16bit, 8bit or Bc7 texture data. After which we upload everything to the GPU.




\subsection{Shaders} \label{implementation:shaders}
To integrate the built data structure into breda, two shaders have been written, \textit{VDB.hsls} and \textit{HDDA.hlsl}. The main way to interface with the data structure is contained in \textit{VDB.hlsl} which has functionality for getting voxels, getting the activity status of certain voxels, and checking what the deepest level of the tree a certain voxel is part of. \textit{HDDA.hlsl} is largely the same as implemented by \cite{museth2013vdb}. The main difference is that we make use of callbacks on the GPU, which is done by passing a template argument to the traversal function. This template argument must implement \textit{empty} and \textit{operator()} which are called after every step, or compiled away if either of them is not used. These step functions are used to write clean yet fast traversal code (as seen in Figure \ref{implementation:hdda_sample}).


\begin{figure}
    \begin{lstlisting}
    // The hdda march method has the following function signature
    // We explicitly say which level of our tree we want to traverse
    template <typename VoxelData, typename VoxelFn>
    void march(inout VoxelFn fn, Layer callbackLayer);

    // We define a struct which contains our traversal payload
    struct FirstDensityFn {
        float4 color;
    
        bool operator()(float voxelData, float t0, float t1, uint dataIndex) {
            float chunkIndex = voxelData * 360;
            color = float4(hsvToRgb(chunkIndex, 1, 1), 1);
            return false; // we dont want to continue traversal
        }
        bool empty(float t0, float t1, uint dataIndex) { 
            return true; // we continue traversal
        }
    };

    // Now we can simply perform our HDDA traversal as follows
    float4 traverseVolume(){
        Hdda hdda = Hdda::new_(volumeGrid, ray, inverseRay);
        FirstDensityFn fn;
        fn.color = float4(0,0,0,0);
        hdda.march<float>(fn, LayerVoxels); 
        return fn.color;
    }
\end{lstlisting}
    \caption{Simplified outline of the HDDA api.}\label{implementation:hdda_sample}
\end{figure}


\subsection{Compression} \label{implementation:compression}
As said in Sections \ref{approach:texture_compression} and \ref{approach:clustering_similar_nodes}, there are two types of compression of the voxel data going on. First we will have a look at how cluster similar bricks. This is largely done by using NDarray \cite{NDarray} for different linear algebra methods. We parse our voxel data into a 2D matrix where every brick is one row. Then we calculate the variance of each brick, divide that by the bricks mean to get a normalized variance, and reject the brick if variance is higher than our set threshold. This way we only keep bricks which have low variance and thus have a low likelyhood of containing unique features. After which we run k-means on all low variance bricks, with a given k and number of iterations. Unfortunately this can be quite an expansive step as k-means has an algorithmic complexity of $O(nk)$ where n is the number of bricks in this case, and k the number of requested new bricks. So when both are large this step will become unpractical. However, most of the low variance bricks can be represented by a very small number of new bricks. After we have a new set of bricks we just have to fix the pointers of our L3 nodes and merge the filtered high variance bricks with the new bricks, and we are done. In Figure \ref{fig:implementation:compression:cluster} we see the results of this compression technique.

\begin{figure}[H]
    \centering
    \subfloat[]{
        \includegraphics[width=0.45\textwidth]{figures/pre_clustered_memory.png} \label{fig:implementation:compression:pre_cluster}
    }
    \hfill
    \subfloat[]{
        \includegraphics[width=0.45\textwidth]{figures/post_clustered_memory.png} \label{fig:implementation:compression:post_cluster}
    }
    \hfill
    \subfloat[]{
        \begin{tabular}{ | c | c | c | c |}
            \hline
            \textbf{k} & \textbf{variance threshold} & \textbf{iterations} & \textbf{RMSE} \\
            \hline
            3          & 4                           & 3                   & 3             \\
            \hline
        \end{tabular}
    }
    \caption{The results of our clustering compression technique. All of these results use Bc7 encoding. Figure \ref{fig:implementation:compression:pre_cluster} shows a slice out of the voxel brick data texture on the GPU. There are visible long chains of black or otherwise greyscale slices which means that these bricks are mostly homogeneous inside that brick. In Figure \ref{fig:implementation:compression:post_cluster} we again see a slice of the voxel brick data texture, but this time after running our clustering algorithm. There are visibly fewer patches greyscale bricks when compared to figure \ref{fig:implementation:compression:pre_cluster}. This shows us that we are actually removing bricks which are homogeneous, and keeping unique nodes.} \label{fig:implementation:compression:cluster}
\end{figure}


\noindent
Texture block compression is done after rearranging the data from a buffer layout to a texture layout. With this data layout we can reduce the floating pooint precision, or even use the existing intel texture compressor \cite{ISPCTextureCompressor} to encode our data into Bc7. After doing this we still have to tell our backend what the format is of our texture, and then we are done. We can reuse our hlsl code for all formats because hlsl automatically samples different floating point types correctly.  In Figure \ref{fig:implementation:compression:bc} we see the results of this compression technique.

\begin{figure}[H]
    \centering
    %\subfloat[]{
    %    \includegraphics[width=0.45\textwidth]{}
    %}
    %\hfill
    %\subfloat[]{
    %    \includegraphics[width=0.45\textwidth]{}
    %}

    \caption{} \label{fig:implementation:compression:bc}
\end{figure}


\subsection{VDB viewer} \label{implementation:vdb_viewer}
A prototyping application was created for visualizing VDB files. This application can be used to load a single VDB file and display multiple debug views of the model as can be seen in Figure \ref{implementation:vdb_viewer:debug_views}. This application also allows quick testing of compression schemes as it bypasses the standard asset pipeline system that was discussed in section \ref{implementation:asset_pipeline}.

\begin{figure}[H]
    \centering
    \subfloat[Shaded by accumulating density along primary ray. The body of the cloud is hollow as can be seen.]{
        \includegraphics[width=0.45\textwidth]{figures/disney_cloud_half_res_shaded.png}
    }
    \hfill
    \subfloat[Shaded by depth of first hit voxel.]{
        \includegraphics[width=0.45\textwidth]{figures/disney_cloud_half_res_depth.png}
    }
    \hfill
    \subfloat[Shaded by index into the voxel index. Shown is a conversion from index to hue using the following formula: $x + y\times dim\_size + z\times dim\_size^2$. The striped pattern is a result of bricks ($8^3$ voxels) are a combination two texture slices, these are the altering index colors. The larger shifts in color, which are in very specific cubic regions, correlate to the different level 2 internal nodes.]{
        \includegraphics[width=0.45\textwidth]{figures/disney_cloud_half_res_index.png}
    }
    \hfill
    \subfloat[Shaded by density of first hit voxel, where a low density is red and a high density results in different hue's. Overall the entire outside of the cloud only shows low density voxels, but there are some spots where deeper voxels are visible which have a higher density.]{
        \includegraphics[width=0.45\textwidth]{figures/disney_cloud_half_res_first_temp.png}
    }
    \caption{Some of the shading options of the VDB viewer application. All renders are done using the half resolution version of the Disney cloud \cite{DisneyCloud}. } \label{implementation:vdb_viewer:debug_views}
\end{figure}